{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to TensorFlow and Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "* conda install tensorflow\n",
    "* https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is TensorFlow?\n",
    "\n",
    "* TensorFlow is an open-source software library for dataflow programming across a range of tasks. \n",
    "* It is a symbolic math library, and is also used for machine learning applications such as neural networks. \n",
    "\n",
    "#### Why use TensorFlow?\n",
    "\n",
    "* Very large and active community (compare with other machine learning frameworks such as H2O)\n",
    "* Low-level and high-level interfaces to network training\n",
    "* Tensorboard is the powerful visualization suite which is developed to track both the network topology and performance, making debugging even simpler.\n",
    "* Written in Python (some parts in C++)\n",
    "* Supports GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "* Keras is a simple-to-use but powerful deep learning library for Python\n",
    "* A high-level, intuitive API for Deep Learning\n",
    "* Easy to define neural networks, then automatically handles execution.\n",
    "* A simple, modular interface which allows focus on learning and enables fast experimentation.\n",
    "\n",
    "because\n",
    "\n",
    "* It is actually a user-friendly wrapper on top of tensorflow\n",
    "* It hides the low level details and make the deep learning easier to build\n",
    "* But it also hides those fine tuning on tensorflow\n",
    "\n",
    "**Because of its popularity and ease of use, keras is now bundled with tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist is a dataset of 28x28 images of handwritten digits and their labels. Now we unpack images to x_train/x_test and labels to y_train/y_test\n",
    "\n",
    "| ![mnist digits](MnistExamplesModified.png) |\n",
    "|:--:|\n",
    "\n",
    "#### Now we unpack images to x_train/x_test and labels to y_train/y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()  \n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# protip - visually inspect your data\n",
    "i = randint(0, x_train.shape[0])\n",
    "pyplot.imshow(x_train[i], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data. In this case it is simply divide by 255 because the pixel has the value range [0, 255]\n",
    "\n",
    "<font color='red'>Warning: the below is a wrong way to normalize train and test datasets seperately. They may end up with in different scale. But in this example it is ok because the min is 0 and max is 255 so the two datasets will have the same scale.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00393124, 0.02332955, 0.02620568,\n",
       "        0.02625207, 0.17420356, 0.17566281, 0.28629534, 0.05664824,\n",
       "        0.51877786, 0.71632322, 0.77892406, 0.89301644, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05780486, 0.06524513,\n",
       "        0.16128198, 0.22713296, 0.22277047, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.368094  , 0.3747499 ,\n",
       "        0.79066747, 0.67980478, 0.61494005, 0.45002403, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12250613, 0.45858525, 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32420121, 0.15214552, 0.17865984,\n",
       "        0.25626376, 0.1573102 , 0.12298801, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04500225, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.28826244,\n",
       "        0.26543758, 0.34149427, 0.31128482, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1541463 , 0.28272888,\n",
       "        0.18358693, 0.37314701, 0.33153488, 0.26569767, 0.01601458,\n",
       "        0.        , 0.05945042, 0.19891229, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0253731 ,\n",
       "        0.00171577, 0.22713296, 0.33153488, 0.11664776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20500962, 0.33153488, 0.24625638, 0.00291174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01622378, 0.24897876, 0.32790981, 0.10191096,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04586451, 0.31235677, 0.32757096,\n",
       "        0.23335172, 0.14931733, 0.00129164, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10498298, 0.34940902,\n",
       "        0.3689874 , 0.34978968, 0.15370495, 0.04089933, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06551419,\n",
       "        0.27127137, 0.34978968, 0.32678448, 0.245396  , 0.05882702,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02333517, 0.12857881, 0.32549285, 0.41390126, 0.40743158,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32161793, 0.41390126, 0.54251585,\n",
       "        0.20001074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06697006,\n",
       "        0.18959827, 0.25300993, 0.32678448, 0.41390126, 0.45100715,\n",
       "        0.00625034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05110617, 0.19182076, 0.33339444,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.40899334, 0.39653769,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04117838, 0.16813739, 0.28960162, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.25961929, 0.12760592, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04431706, 0.11961607,\n",
       "        0.36545809, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.28877275, 0.111988  , 0.00258328, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05298497, 0.42752138, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.25273681, 0.11646967,\n",
       "        0.01312603, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37491383,\n",
       "        0.56222061, 0.66525569, 0.63253163, 0.48748768, 0.45852825,\n",
       "        0.43408872, 0.359873  , 0.17428513, 0.01425695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92705966,\n",
       "        0.82698729, 0.74473314, 0.63253163, 0.4084877 , 0.24466922,\n",
       "        0.22648107, 0.02359823, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = normalize(x_train, axis=1)  # scales data between 0 and 1\n",
    "x_test = normalize(x_test, axis=1)  # scales data between 0 and 1\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build a basic feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### takes our 28x28 and makes it 1x784 to feed the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build two hidden layers\n",
    "* each layer is a simple fully-connected layer, 128 neurons\n",
    "* The activation function is relu, short for rectified linear. Currently, relu is the activation function you should just default to. There are many more to test for sure, but, if you don't know what to use, use relu to start\n",
    "* The output of relu is ƒ(x) = max(0,x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(128, activation=tf.nn.relu)) \n",
    "#model.add(Dense(128, activation=tf.nn.relu))  \n",
    "model.add(Dense(16, activation=tf.nn.relu)) \n",
    "model.add(Dense(16, activation=tf.nn.relu))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the output layers. 10 units for 10 classes. Softmax for probability distribution\n",
    "* softmax converts neural activation to probability of category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation=tf.nn.softmax))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as tensorflow, you need to provide the loss function and optimizer. Here we use SGD and categorical_crossentropy.\n",
    "\n",
    "#### A lot of losses to choose from at https://keras.io/api/losses/\n",
    "\n",
    "* Probabilistic losses\n",
    "    - BinaryCrossentropy class\n",
    "    - CategoricalCrossentropy class\n",
    "    - SparseCategoricalCrossentropy class\n",
    "    - Poisson class\n",
    "    - binary_crossentropy function\n",
    "    - categorical_crossentropy function\n",
    "    - sparse_categorical_crossentropy function\n",
    "    - poisson function\n",
    "    - KLDivergence class\n",
    "    - kl_divergence function\n",
    "    - etc...\n",
    "    \n",
    "* difference between sparse_categorical_crossentropy and categorical_crossentropy\n",
    "    * categorical_crossentropy (cce) uses a one-hot array to calculate the probability,\n",
    "    * sparse_categorical_crossentropy (scce) uses a category index\n",
    "    \n",
    "### Available optimizers at https://keras.io/api/optimizers/\n",
    "* SGD\n",
    "* RMSprop\n",
    "* Adam\n",
    "* Adadelta\n",
    "* Adagrad\n",
    "* Adamax\n",
    "* Nadam\n",
    "* Ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', # usually we use 'adam' as default to start with. Now we use sgd to compare with last week's model\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])  # what to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's ready to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2528 - accuracy: 0.6460\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4924 - accuracy: 0.8610\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4027 - accuracy: 0.8847\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3667 - accuracy: 0.8955\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3465 - accuracy: 0.9014\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3332 - accuracy: 0.9043\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3232 - accuracy: 0.9076\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3156 - accuracy: 0.9102\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3089 - accuracy: 0.9119\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3043 - accuracy: 0.9140\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3008 - accuracy: 0.9147\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2980 - accuracy: 0.9154\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2969 - accuracy: 0.9168\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2954 - accuracy: 0.9159\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2945 - accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x319553640>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15) #repeat 15 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (32, 784)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (32, 16)                  12560     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 16)                  272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32, 10)                  170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13002 (50.79 KB)\n",
      "Trainable params: 13002 (50.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and evaluate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2878 - accuracy: 0.9192\n",
      "0.287776917219162\n",
      "0.9192000031471252\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  \n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 4\n",
      "prediction 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x31b51db20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=randint(0,9999)\n",
    "print(\"label\",y_test[index])\n",
    "print(\"prediction\", max([(v, k) for k, v in enumerate(pred[index])])[1])\n",
    "pyplot.imshow(x_test[index], cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://victorzhou.com/blog/intro-to-neural-networks/\n",
    "\n",
    "https://github.com/vuptran/introduction-to-neural-networks/blob/master/intro_neural_network.ipynb\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/deep-learning-python\n",
    "\n",
    "https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/\n",
    "\n",
    "https://drive.google.com/file/d/1AGuKRLssV0bjXrV7YNzwKGuHUzExS0jF/view\n",
    "\n",
    "https://github.com/brianspiering/keras-intro/blob/master/keras-intro.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

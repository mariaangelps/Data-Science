{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGhoHtzhIj5k"
   },
   "source": [
    "# Introduction to `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hW6O_39pSlfP"
   },
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "- open-source Python library\n",
    "- extract data from HTML files\n",
    "- understands HTML structure by working with a [parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser) (`lxml`, `html5lib`, etc.) \n",
    "- [BeautifulSoup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for reference\n",
    "<br> <br>\n",
    "\n",
    "`BeautifulSoup` does not actually gather information from the web.  We will use the `requests` library for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDuD_qj9IxLP"
   },
   "source": [
    "# Learn to Scrape with Simple Inline HTML\n",
    "\n",
    "Let's start with this simple HTML page given below as a string: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H00yNF3_uuKB"
   },
   "outputs": [],
   "source": [
    "simple_html = \"\"\"\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <style>\n",
    "    li {font-size: 18px;}\n",
    "  </style\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div style=\"border-style: dotted; padding: 10px\">\n",
    "    <h1>Today's Learning Objectives</h1>\n",
    "    <ul>\n",
    "      <li>Decipher basic HTML</li>\n",
    "      <li>Retrieve information from Internet</li>\n",
    "      <li>Parse web data</li>\n",
    "      <li>Gather and prepare data systematically</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "  </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AqWBqN70t-e"
   },
   "source": [
    "Now we will tell Python to render this string as HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WR7vpgdGvQRy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "\n",
       "<head>\n",
       "  <style>\n",
       "    li {font-size: 18px;}\n",
       "  </style\n",
       "</head>\n",
       "\n",
       "<body>\n",
       "  <div style=\"border-style: dotted; padding: 10px\">\n",
       "    <h1>Today's Learning Objectives</h1>\n",
       "    <ul>\n",
       "      <li>Decipher basic HTML</li>\n",
       "      <li>Retrieve information from Internet</li>\n",
       "      <li>Parse web data</li>\n",
       "      <li>Gather and prepare data systematically</li>\n",
       "    </ul>\n",
       "    <br>\n",
       "  </div>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(simple_html)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JbPxSix3MP6"
   },
   "source": [
    "This simple \"page\" contains a list of learning objectives for today's workshop. Now we will see how `BeautifulSoup` can extract information from this HTML.\n",
    "\n",
    "First we need to import `BeautifulSoup` and parse the HTML string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NTv9j2G5Omt"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxqSZc7UPxbx"
   },
   "outputs": [],
   "source": [
    "soup = bs(simple_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08WUfmF0QIKz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<html>\n",
       "<head>\n",
       "<style></style></head></html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsv1EITAQOqp"
   },
   "source": [
    "When we print out `soup`, it looks like `BeautifulSoup` knows how to navigate through the HTML DOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7JIsSw3Qgjn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkjBrNoJLNVc"
   },
   "source": [
    "### Find by tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6Tphk26QlYp"
   },
   "source": [
    "We begin by using the `find()` method to extract the header of our HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y19Bk4CHLPsi"
   },
   "outputs": [],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POZRpITeRWLN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find('h1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IOnOX64RZTg"
   },
   "source": [
    "`find()` returns a tagged element, but we can grab just the inner HTML text instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24AqJmFpRrNA"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqkdCh4URrov"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "type(soup.find('h1').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WliT3c4pR0mj"
   },
   "source": [
    "We now have a way to extract text from a webpage -- powerful stuff!  \n",
    "\n",
    "What do you think will be returned if we look for list tags (`li`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JyfRsaFnRrrg"
   },
   "outputs": [],
   "source": [
    "soup.find('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yp3vUeZSEoC"
   },
   "source": [
    "**Warning**: `BeautifulSoup` returns ONLY the FIRST matching element when we use `find()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJ75L1fvLP6l"
   },
   "source": [
    "### Find all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbOtBcr6Sg0E"
   },
   "source": [
    "If we would like `BeautifulSoup` to return ALL matching elements, we can use `find_all()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mGMr9VMLUX1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0k6_ZBXTkuu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find_all('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHno1ME9Tx-I"
   },
   "source": [
    "Using `find_all()` yields a result set containing all of list elements on the \"page.\"  You can basically think of a result set as actinly like a list. \n",
    "\n",
    "**Warning**: `BeautifulSoup` does not allow you to apply `.text` to a result set.  The following code **will fail**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuCGOhboTkxY"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mli\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.9/site-packages/bs4/element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[1;32m   2435\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "soup.find_all('li').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4fu3oHxUhOP"
   },
   "source": [
    "Instead, you must apply `.text` to each item in the result set individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdAvyYN6UWig"
   },
   "outputs": [],
   "source": [
    "for item in soup.find_all('li'):\n",
    "  print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKEltegqUWlT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_objectives = [item.text for item in soup.find_all('li')]\n",
    "\n",
    "learning_objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJl4-qR0U_oG"
   },
   "source": [
    "**Tip**: The two **most common mistakes** I see in web scraping with `BeautifulSoup` are:\n",
    "- Using `find()` when you really want `find_all()`\n",
    "- Attempting to apply `.text` to a result set like the output of `find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBcOBj8lMQV4"
   },
   "outputs": [],
   "source": [
    "workshop_html = \"\"\"\n",
    "<html>\n",
    "\n",
    "<body>\n",
    "  <h1>Today's Workshop</h1>\n",
    "  <div id='agenda' style=\"background-color: aliceblue\">\n",
    "    <h2>Agenda</h2>\n",
    "    <p>Today's workshop is comprised of three main sections:</p>\n",
    "    <ol>\n",
    "      <li>HTML Basics</li>\n",
    "      <li>Scraping Basics</li>\n",
    "      <li>Scraping Pipeline</li>\n",
    "    </ol>\n",
    "  </div>\n",
    "  \n",
    "  <div id='tools' style='background-color: honeydew'>\n",
    "    <h2>Tools</h2>\n",
    "    <p>You will be learning about two primary Python libraries:</p>  \n",
    "    <ol>\n",
    "      <li>BeautifulSoup</li>\n",
    "      <li>requests</li>\n",
    "    </ol>\n",
    "  </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3wwCI9NJZPz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "\n",
       "<body>\n",
       "  <h1>Today's Workshop</h1>\n",
       "  <div id='agenda' style=\"background-color: aliceblue\">\n",
       "    <h2>Agenda</h2>\n",
       "    <p>Today's workshop is comprised of three main sections:</p>\n",
       "    <ol>\n",
       "      <li>HTML Basics</li>\n",
       "      <li>Scraping Basics</li>\n",
       "      <li>Scraping Pipeline</li>\n",
       "    </ol>\n",
       "  </div>\n",
       "  \n",
       "  <div id='tools' style='background-color: honeydew'>\n",
       "    <h2>Tools</h2>\n",
       "    <p>You will be learning about two primary Python libraries:</p>  \n",
       "    <ol>\n",
       "      <li>BeautifulSoup</li>\n",
       "      <li>requests</li>\n",
       "    </ol>\n",
       "  </div>\n",
       "</body>\n",
       "\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(workshop_html)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpdrMjBgaQ3i"
   },
   "source": [
    "> Parse `workshop_html` with `BeautifulSoup`.  Find the main header text (`h1`) and save it in a variable.  Verify that you have the text by checking the `type` of your variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6adKDP0bEKR"
   },
   "outputs": [],
   "source": [
    "soup = bs(workshop_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6adKDP0bEKR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's Workshop\n"
     ]
    }
   ],
   "source": [
    "header = soup.find('h1').text\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6adKDP0bEKR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mhjw8y_JbNHd"
   },
   "source": [
    "Now find all the paragraphs in `workshop_html` and print out the text that you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKUg-aurb8bM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's workshop is comprised of three main sections:\n",
      "You will be learning about two primary Python libraries:\n"
     ]
    }
   ],
   "source": [
    "soup.find_all('p')\n",
    "\n",
    "for paragraph in soup.find_all('p'):\n",
    "  print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXuDZ968cTkT"
   },
   "source": [
    "Create a list of all of the agenda items for today's workshop.  Be sure to store only the TEXT for the AGENDA items!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUYIOQG0ciZP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTML Basics', 'Scraping Basics', 'Scraping Pipeline']\n"
     ]
    }
   ],
   "source": [
    "agenda_items = [li.text for li in soup.find_all('li')[:3]]\n",
    "\n",
    "print(agenda_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyvvjM2tcic1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTML Basics', 'Scraping Basics', 'Scraping Pipeline']\n"
     ]
    }
   ],
   "source": [
    "#Later we will learn a better way: \n",
    "#  First look for the div that contains the agenda items\n",
    "\n",
    "agenda_div = soup.find('div', id='agenda')\n",
    "\n",
    "agenda_items = [li.text for li in agenda_div.find_all('li')]\n",
    "\n",
    "print(agenda_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iqq1HAHnJZ4b"
   },
   "source": [
    "# Scrape Test Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENkQA206dhqK"
   },
   "source": [
    "In the last exercise, we found out that oftentimes using only the HTML tags alone won't be granular enough.  \n",
    "\n",
    "Let's work with a more complicated HTML file to see what other options are available.\n",
    "\n",
    "First download this file to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj5tg_MnnwB7"
   },
   "outputs": [],
   "source": [
    "bootcamp_html = open('data/bootcamp.html').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-q2zzBCYog7r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "    <head>\n",
      "        <title>Data Science Bootcamp Info</title>\n",
      "\n",
      "        <style>\n",
      "            body {\n",
      "                background-color: cornsilk;\n",
      "            }\n",
      "\n",
      "            h1 {\n",
      "                font-size: 40px;\n",
      "                font-family: courier new, arial;\n",
      "                text-align: center;\n",
      "                margin-top: 50px;\n",
      "            }\n",
      "\n",
      "            a {\n",
      "                color: #411B2D;\n",
      "                font-size: 20px;\n",
      "            }\n",
      "\n",
      "            p {\n",
      "                font-size: 20px;\n",
      "            }\n",
      "\n",
      "            a:hover{\n",
      "                color: white;\n",
      "                background-color: #411B2D;\n",
      "            }\n",
      "\n",
      "            #toolbar {\n",
      "                background-color: #F3B643;\n",
      "                font-family: courier new, arial;\n",
      "                font-weight: bold;\n",
      "                font-size: 16px;\n",
      "                display: flex;\n",
      "                justify-content: space-around;\n",
      "                flex-direction: row;\n",
      "                border: 1px solid black;\n",
      "                border-radius: 1px;\n",
      "                margin: auto;\n",
      "                width: 95%;\n",
      "                padding: 20px;\n",
      "            }\n",
      "\n",
      "            .events {\n",
      "                margin: auto;\n",
      "                width: 60%;\n",
      "                margin-top: 50px;\n",
      "            }\n",
      "\n",
      "            #tomorrow {\n",
      "                margin-bottom: 50px;\n",
      "            }\n",
      "\n",
      "        </style>\n",
      "    </head>\n",
      "    \n",
      "    <body>\n",
      "        <h1>Data Science Bootcamp</h1>\n",
      "        <div id=\"toolbar\">\n",
      "            <a href=\"https://us.dsbc.org/about/\">WHAT IS DSBC?</a>\n",
      "            <a href=\"https://us.dsbc.org/tutorials/\">TUTORIAL SCHEDULE</a>\n",
      "            <a href=\"https://us.dsbc.org/speaking/\">SPEAKING AT DSBC</a>\n",
      "        </div>\n",
      "\n",
      "        <div id=\"today\" class=\"events\">\n",
      "            <h2>A Selection of Today's Events</h2>\n",
      "            <p> Room 309, 9:00 am - <a href=\"https://us.dsbc.org/schedule/presentation/50/\">Foundations of Numerical Computing in Python</a></p>\n",
      "            <p> Room 315, 9:00 am - <a href=\"https://us.dsbc.org/schedule/presentation/72/\">It's Officially Legal so Let's Scrape the Web</a></p>\n",
      "            <p> Room 317, 1:20 pm - <a href=\"https://us.dsbc.org/schedule/presentation/54/\">A Beginner's Guide to Befriending Python</a></p>\n",
      "            <p> Room 318, 1:20 pm -<a href=\"https://us.dsbc.org/schedule/presentation/55/\">Scalable Computing with Dask</a></p>\n",
      "        </div>\n",
      "\n",
      "        <div id=\"tomorrow\" class=\"events\">\n",
      "            <h2>Coming Up Tomorrow</h2>\n",
      "            <p> Room 316, 9:00 am - <a href=\"https://us.dsbc.org/schedule/presentation/63/\">Creating a Great Python Package</a></p>\n",
      "            <p> Room 319, 9:00 am - <a href=\"https://us.dsbc.org/schedule/presentation/45/\">Minimum Viable Documentation</a></p>\n",
      "            <p> Room 309, 1:20 pm - <a href=\"https://us.dsbc.org/schedule/presentation/74/\">Effective Data Visualization</a>\n",
      "        </div>\n",
      "\n",
      "\n",
      "    </body>\n",
      "    \n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bootcamp_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDPP_5ygqW7P"
   },
   "source": [
    "Since our HTML is a string, we can parse it with `BeautifulSoup` and begin collecting data.  \n",
    "\n",
    "Let's say we are interested in gathering titles and links of events happening today.  Links can be found by looking for anchor, `a`, tags.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B5Oydm6rIDq"
   },
   "outputs": [],
   "source": [
    "soup = bs(bootcamp_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PK4gJLPwrVPM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://us.dsbc.org/about/\">WHAT IS DSBC?</a>,\n",
       " <a href=\"https://us.dsbc.org/tutorials/\">TUTORIAL SCHEDULE</a>,\n",
       " <a href=\"https://us.dsbc.org/speaking/\">SPEAKING AT DSBC</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/50/\">Foundations of Numerical Computing in Python</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/72/\">It's Officially Legal so Let's Scrape the Web</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/54/\">A Beginner's Guide to Befriending Python</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/55/\">Scalable Computing with Dask</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/63/\">Creating a Great Python Package</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/45/\">Minimum Viable Documentation</a>,\n",
       " <a href=\"https://us.dsbc.org/schedule/presentation/74/\">Effective Data Visualization</a>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HaEHZgVslih"
   },
   "source": [
    "Whoa -- there are a lot more links on this page other than today's events!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50z8xhqlLfTL"
   },
   "source": [
    "### Find by attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8J3lOYFsvdp"
   },
   "source": [
    "In order to drill down to just the links we are interested in, notice that today's events are contained within a `div` that has `id=today`.  We can first isolate this `div` by searching for it by its `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ljh-i2WLhDJ"
   },
   "outputs": [],
   "source": [
    "today_div = soup.find(id='today')\n",
    "\n",
    "today_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFX6VVDRtFj3"
   },
   "outputs": [],
   "source": [
    "type(today_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSbVBUzltRIa"
   },
   "source": [
    "Now we will look for all of the anchor tags that are contained within this division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJBi-y4StLqd"
   },
   "outputs": [],
   "source": [
    "today_div.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmkC8X_4xnbC"
   },
   "source": [
    "**Tip**:  You can find elements by pretty much any attribute.  Let's find elements with that are members of the `events` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1IBgegQxLgZ"
   },
   "outputs": [],
   "source": [
    "soup.find_all(class_ = 'events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFKaUQeczI8S"
   },
   "source": [
    "Passing a dictionary of attributes works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cPgx8kgy4lc"
   },
   "outputs": [],
   "source": [
    "soup.find_all(attrs={'class':'events', 'id': 'tomorrow'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vdtgdj92Lm0S"
   },
   "source": [
    "### Retrieve attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ERJqjn_tZsC"
   },
   "source": [
    "If we want to just get the names of today's events, we can simply cycle through today's links and collect the `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gjThbpwtLui"
   },
   "outputs": [],
   "source": [
    "today_text = [link.text for link in today_div.find_all('a')]\n",
    "\n",
    "today_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTnrWzSGxdIN"
   },
   "source": [
    "But what would we do if we wanted the **hyperlinks** to each of those events?\n",
    "\n",
    "`BeautifulSoup` allows you to retrieve element attributes.  You will reference these using the same syntax as dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dqcWf7jLs_t"
   },
   "outputs": [],
   "source": [
    "today_div.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgSsqg2czq9-"
   },
   "outputs": [],
   "source": [
    "today_div.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBC1yquizvMZ"
   },
   "outputs": [],
   "source": [
    "type(today_div.find('a')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPvUjoF9zy8l"
   },
   "outputs": [],
   "source": [
    "today_links = [link['href'] for link in today_div.find_all('a')]\n",
    "\n",
    "today_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8rfPI2m1bmM"
   },
   "source": [
    "Create a list of tuples for each of tomorrow's events.  The first element in your tuples will be the event title and the second will be the event link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoiUcz0aL1fJ"
   },
   "outputs": [],
   "source": [
    "tomorrow_tuples = [(a.text, a['href']) for a in soup.find(id='tomorrow').find_all('a')]\n",
    "\n",
    "tomorrow_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5DAy_WZ08mh"
   },
   "source": [
    "Using `bootcamp_html` find the header text for today's and tomorrow's events by referencing the `events` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoJ_Rdc91uie"
   },
   "outputs": [],
   "source": [
    "event_headers = [div.find('h2') for div in soup.find_all(class_='events')]\n",
    "\n",
    "event_header_text = [header.text for header in event_headers]\n",
    "\n",
    "event_header_text"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyCon2020_Scraping_Basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
